[2025-04-21T02:05:33.557-0300] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-21T02:05:33.573-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T02:05:33.581-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T02:05:33.582-0300] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-04-21T02:05:33.604-0300] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): iniciando_pipeline> on 2025-04-20 00:00:00+00:00
[2025-04-21T02:05:33.614-0300] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'DW', 'iniciando_pipeline', 'scheduled__2025-04-20T00:00:00+00:00', '--job-id', '24', '--raw', '--subdir', 'DAGS_FOLDER/DW.py', '--cfg-path', '/tmp/tmphwxsyuoh']
[2025-04-21T02:05:33.615-0300] {standard_task_runner.py:105} INFO - Job 24: Subtask iniciando_pipeline
[2025-04-21T02:05:33.621-0300] {logging_mixin.py:190} WARNING - /home/lenovo/miniconda3/envs/worker/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=15153) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-04-21T02:05:33.622-0300] {standard_task_runner.py:72} INFO - Started process 15261 to run task
[2025-04-21T02:05:33.667-0300] {task_command.py:467} INFO - Running <TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [running]> on host DESKTOP-1GIT60U.
[2025-04-21T02:05:33.758-0300] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='DW' AIRFLOW_CTX_TASK_ID='iniciando_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-04-20T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-20T00:00:00+00:00'
[2025-04-21T02:05:33.760-0300] {taskinstance.py:731} INFO - ::endgroup::
[2025-04-21T02:05:33.777-0300] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-21T02:05:33.779-0300] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'echo "ðŸš€ Iniciando o pipeline..."']
[2025-04-21T02:05:33.793-0300] {subprocess.py:99} INFO - Output:
[2025-04-21T02:05:33.794-0300] {subprocess.py:106} INFO - ðŸš€ Iniciando o pipeline...
[2025-04-21T02:05:33.795-0300] {subprocess.py:110} INFO - Command exited with return code 0
[2025-04-21T02:05:33.823-0300] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-04-21T02:05:33.825-0300] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=DW, task_id=iniciando_pipeline, run_id=scheduled__2025-04-20T00:00:00+00:00, execution_date=20250420T000000, start_date=20250421T050533, end_date=20250421T050533
[2025-04-21T02:05:33.879-0300] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-21T02:05:33.903-0300] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-21T02:05:33.912-0300] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-21T02:12:57.945-0300] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-21T02:12:57.963-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T02:12:57.971-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T02:12:57.972-0300] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-04-21T02:12:57.997-0300] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): iniciando_pipeline> on 2025-04-20 00:00:00+00:00
[2025-04-21T02:12:58.009-0300] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'DW', 'iniciando_pipeline', 'scheduled__2025-04-20T00:00:00+00:00', '--job-id', '35', '--raw', '--subdir', 'DAGS_FOLDER/DW.py', '--cfg-path', '/tmp/tmpm7k5977e']
[2025-04-21T02:12:58.011-0300] {standard_task_runner.py:105} INFO - Job 35: Subtask iniciando_pipeline
[2025-04-21T02:12:58.015-0300] {logging_mixin.py:190} WARNING - /home/lenovo/miniconda3/envs/worker/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=18735) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-04-21T02:12:58.016-0300] {standard_task_runner.py:72} INFO - Started process 18837 to run task
[2025-04-21T02:12:58.061-0300] {task_command.py:467} INFO - Running <TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [running]> on host DESKTOP-1GIT60U.
[2025-04-21T02:12:58.160-0300] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='DW' AIRFLOW_CTX_TASK_ID='iniciando_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-04-20T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-20T00:00:00+00:00'
[2025-04-21T02:12:58.161-0300] {taskinstance.py:731} INFO - ::endgroup::
[2025-04-21T02:12:58.189-0300] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-21T02:12:58.191-0300] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'echo "ðŸš€ Iniciando o pipeline..."']
[2025-04-21T02:12:58.207-0300] {subprocess.py:99} INFO - Output:
[2025-04-21T02:12:58.209-0300] {subprocess.py:106} INFO - ðŸš€ Iniciando o pipeline...
[2025-04-21T02:12:58.209-0300] {subprocess.py:110} INFO - Command exited with return code 0
[2025-04-21T02:12:58.240-0300] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-04-21T02:12:58.241-0300] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=DW, task_id=iniciando_pipeline, run_id=scheduled__2025-04-20T00:00:00+00:00, execution_date=20250420T000000, start_date=20250421T051257, end_date=20250421T051258
[2025-04-21T02:12:58.313-0300] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-21T02:12:58.350-0300] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-21T02:12:58.360-0300] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-21T02:27:11.395-0300] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-21T02:27:11.413-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T02:27:11.420-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T02:27:11.421-0300] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-04-21T02:27:11.448-0300] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): iniciando_pipeline> on 2025-04-20 00:00:00+00:00
[2025-04-21T02:27:11.458-0300] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'DW', 'iniciando_pipeline', 'scheduled__2025-04-20T00:00:00+00:00', '--job-id', '41', '--raw', '--subdir', 'DAGS_FOLDER/DW.py', '--cfg-path', '/tmp/tmparra2sim']
[2025-04-21T02:27:11.459-0300] {standard_task_runner.py:105} INFO - Job 41: Subtask iniciando_pipeline
[2025-04-21T02:27:11.465-0300] {logging_mixin.py:190} WARNING - /home/lenovo/miniconda3/envs/worker/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=22622) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-04-21T02:27:11.466-0300] {standard_task_runner.py:72} INFO - Started process 22724 to run task
[2025-04-21T02:27:11.506-0300] {task_command.py:467} INFO - Running <TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [running]> on host DESKTOP-1GIT60U.
[2025-04-21T02:27:11.593-0300] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='DW' AIRFLOW_CTX_TASK_ID='iniciando_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-04-20T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-20T00:00:00+00:00'
[2025-04-21T02:27:11.595-0300] {taskinstance.py:731} INFO - ::endgroup::
[2025-04-21T02:27:11.610-0300] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-21T02:27:11.611-0300] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'echo "ðŸš€ Iniciando o pipeline..."']
[2025-04-21T02:27:11.626-0300] {subprocess.py:99} INFO - Output:
[2025-04-21T02:27:11.627-0300] {subprocess.py:106} INFO - ðŸš€ Iniciando o pipeline...
[2025-04-21T02:27:11.628-0300] {subprocess.py:110} INFO - Command exited with return code 0
[2025-04-21T02:27:11.664-0300] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-04-21T02:27:11.665-0300] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=DW, task_id=iniciando_pipeline, run_id=scheduled__2025-04-20T00:00:00+00:00, execution_date=20250420T000000, start_date=20250421T052711, end_date=20250421T052711
[2025-04-21T02:27:11.722-0300] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-21T02:27:11.744-0300] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-21T02:27:11.755-0300] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-21T02:36:09.162-0300] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-21T02:36:09.181-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T02:36:09.189-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T02:36:09.190-0300] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-04-21T02:36:09.220-0300] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): iniciando_pipeline> on 2025-04-20 00:00:00+00:00
[2025-04-21T02:36:09.233-0300] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'DW', 'iniciando_pipeline', 'scheduled__2025-04-20T00:00:00+00:00', '--job-id', '46', '--raw', '--subdir', 'DAGS_FOLDER/DW.py', '--cfg-path', '/tmp/tmpzashi8o_']
[2025-04-21T02:36:09.235-0300] {standard_task_runner.py:105} INFO - Job 46: Subtask iniciando_pipeline
[2025-04-21T02:36:09.240-0300] {logging_mixin.py:190} WARNING - /home/lenovo/miniconda3/envs/worker/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=25938) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-04-21T02:36:09.241-0300] {standard_task_runner.py:72} INFO - Started process 26040 to run task
[2025-04-21T02:36:09.304-0300] {task_command.py:467} INFO - Running <TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [running]> on host DESKTOP-1GIT60U.
[2025-04-21T02:36:09.417-0300] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='DW' AIRFLOW_CTX_TASK_ID='iniciando_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-04-20T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-20T00:00:00+00:00'
[2025-04-21T02:36:09.419-0300] {taskinstance.py:731} INFO - ::endgroup::
[2025-04-21T02:36:09.436-0300] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-21T02:36:09.437-0300] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'echo "ðŸš€ Iniciando o pipeline..."']
[2025-04-21T02:36:09.451-0300] {subprocess.py:99} INFO - Output:
[2025-04-21T02:36:09.453-0300] {subprocess.py:106} INFO - ðŸš€ Iniciando o pipeline...
[2025-04-21T02:36:09.453-0300] {subprocess.py:110} INFO - Command exited with return code 0
[2025-04-21T02:36:09.483-0300] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-04-21T02:36:09.485-0300] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=DW, task_id=iniciando_pipeline, run_id=scheduled__2025-04-20T00:00:00+00:00, execution_date=20250420T000000, start_date=20250421T053609, end_date=20250421T053609
[2025-04-21T02:36:09.539-0300] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-21T02:36:09.563-0300] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-21T02:36:09.579-0300] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-21T08:55:48.062-0300] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-21T08:55:48.072-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T08:55:48.077-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T08:55:48.077-0300] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-04-21T08:55:48.093-0300] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): iniciando_pipeline> on 2025-04-20 00:00:00+00:00
[2025-04-21T08:55:48.100-0300] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'DW', 'iniciando_pipeline', 'scheduled__2025-04-20T00:00:00+00:00', '--job-id', '58', '--raw', '--subdir', 'DAGS_FOLDER/DW.py', '--cfg-path', '/tmp/tmpx53pp4cc']
[2025-04-21T08:55:48.101-0300] {standard_task_runner.py:105} INFO - Job 58: Subtask iniciando_pipeline
[2025-04-21T08:55:48.105-0300] {logging_mixin.py:190} WARNING - /home/lenovo/miniconda3/envs/worker/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=35068) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-04-21T08:55:48.105-0300] {standard_task_runner.py:72} INFO - Started process 35164 to run task
[2025-04-21T08:55:48.134-0300] {task_command.py:467} INFO - Running <TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [running]> on host DESKTOP-1GIT60U.
[2025-04-21T08:55:48.188-0300] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='DW' AIRFLOW_CTX_TASK_ID='iniciando_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-04-20T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-20T00:00:00+00:00'
[2025-04-21T08:55:48.189-0300] {taskinstance.py:731} INFO - ::endgroup::
[2025-04-21T08:55:48.198-0300] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-21T08:55:48.199-0300] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'echo "ðŸš€ Iniciando o pipeline..."']
[2025-04-21T08:55:48.207-0300] {subprocess.py:99} INFO - Output:
[2025-04-21T08:55:48.208-0300] {subprocess.py:106} INFO - ðŸš€ Iniciando o pipeline...
[2025-04-21T08:55:48.208-0300] {subprocess.py:110} INFO - Command exited with return code 0
[2025-04-21T08:55:48.229-0300] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-04-21T08:55:48.229-0300] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=DW, task_id=iniciando_pipeline, run_id=scheduled__2025-04-20T00:00:00+00:00, execution_date=20250420T000000, start_date=20250421T115548, end_date=20250421T115548
[2025-04-21T08:55:48.280-0300] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-21T08:55:48.289-0300] {dagrun.py:977} ERROR - Failed to get task for ti <TaskInstance: DW.Meta scheduled__2025-04-20T00:00:00+00:00 [queued]>. Marking it as removed.
[2025-04-21T08:55:48.297-0300] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-21T08:55:48.308-0300] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-21T09:23:28.339-0300] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-21T09:23:28.349-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T09:23:28.354-0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [queued]>
[2025-04-21T09:23:28.354-0300] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-04-21T09:23:28.368-0300] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): iniciando_pipeline> on 2025-04-20 00:00:00+00:00
[2025-04-21T09:23:28.371-0300] {standard_task_runner.py:72} INFO - Started process 38016 to run task
[2025-04-21T09:23:28.373-0300] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'DW', 'iniciando_pipeline', 'scheduled__2025-04-20T00:00:00+00:00', '--job-id', '67', '--raw', '--subdir', 'DAGS_FOLDER/DW.py', '--cfg-path', '/tmp/tmplyx8vvdy']
[2025-04-21T09:23:28.374-0300] {standard_task_runner.py:105} INFO - Job 67: Subtask iniciando_pipeline
[2025-04-21T09:23:28.407-0300] {task_command.py:467} INFO - Running <TaskInstance: DW.iniciando_pipeline scheduled__2025-04-20T00:00:00+00:00 [running]> on host DESKTOP-1GIT60U.
[2025-04-21T09:23:28.471-0300] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='airflow@example.com' AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='DW' AIRFLOW_CTX_TASK_ID='iniciando_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-04-20T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-20T00:00:00+00:00'
[2025-04-21T09:23:28.472-0300] {taskinstance.py:731} INFO - ::endgroup::
[2025-04-21T09:23:28.486-0300] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-21T09:23:28.487-0300] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'echo "ðŸš€ Iniciando o pipeline..."']
[2025-04-21T09:23:28.496-0300] {subprocess.py:99} INFO - Output:
[2025-04-21T09:23:28.497-0300] {subprocess.py:106} INFO - ðŸš€ Iniciando o pipeline...
[2025-04-21T09:23:28.497-0300] {subprocess.py:110} INFO - Command exited with return code 0
[2025-04-21T09:23:28.518-0300] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-04-21T09:23:28.518-0300] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=DW, task_id=iniciando_pipeline, run_id=scheduled__2025-04-20T00:00:00+00:00, execution_date=20250420T000000, start_date=20250421T122328, end_date=20250421T122328
[2025-04-21T09:23:28.546-0300] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-21T09:23:28.562-0300] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-21T09:23:28.571-0300] {local_task_job_runner.py:245} INFO - ::endgroup::
